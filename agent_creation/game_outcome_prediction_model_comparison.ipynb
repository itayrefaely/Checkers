{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1e2b16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T19:00:49.096591Z",
     "start_time": "2023-11-09T19:00:48.180921Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file, including the first row\n",
    "data = pd.read_csv('board_evals.csv', header=None)\n",
    "\n",
    "# Define the column names as a list\n",
    "column_names = ['Score', 'Captured', 'Potential', 'Regular Pawns', 'Kings', 'Capturables', 'Semi Capturables', 'Uncapturables', 'At Middle', 'Far', 'Is Over', 'Outcome']\n",
    "data.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8326e461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T19:00:49.755434Z",
     "start_time": "2023-11-09T19:00:49.097216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Score  Captured  Potential  Regular Pawns  Kings  Capturables  \\\n",
      "0 -1.606480         0          1              0      0            0   \n",
      "1 -1.547084         0          0              0      0            0   \n",
      "2 -1.665875         0          1              0      0            0   \n",
      "3 -1.844062         0         -1              0      0            0   \n",
      "4 -1.309502         0          2              0      0            0   \n",
      "5 -1.428293         0          7              0      0            0   \n",
      "6 -0.715548         1          8              1      0           -1   \n",
      "7 -1.190711         1          0              0      0            0   \n",
      "8 -1.250107         1         -2              0      0            0   \n",
      "9 -1.190711         1          4              0      0            0   \n",
      "\n",
      "   Semi Capturables  Uncapturables  At Middle  Far  Is Over  Outcome  \n",
      "0                 1             -1          1    0        0       -1  \n",
      "1                 0              1          0    0        0        1  \n",
      "2                 0              0          0    0        0       -1  \n",
      "3                 1             -1          0    0        0        1  \n",
      "4                 0              1          1    0        0       -1  \n",
      "5                 2             -2          0    0        0        1  \n",
      "6                 1              0          0    1        0       -1  \n",
      "7                 3             -1          1    0        0        1  \n",
      "8                 1              2         -1    0        0       -1  \n",
      "9                 4             -3          1    0        0        1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Scale the first column values\n",
    "scaler = StandardScaler()\n",
    "data['Score'] = scaler.fit_transform(np.array(data[['Score']]))\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20dc378c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T19:00:50.105938Z",
     "start_time": "2023-11-09T19:00:49.755108Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and the target (y)\n",
    "X = np.array(data.drop(columns=['Outcome']))  # Features (all columns except 'Outcome')\n",
    "y = np.array(data['Outcome'])  # Target variable ('Outcome' column)\n",
    "\n",
    "# Split the data into training (70%) and test (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc29ef5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T19:04:23.391081Z",
     "start_time": "2023-11-09T19:00:50.106080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [10/100], Loss: 0.3845\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [20/100], Loss: 0.3821\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [30/100], Loss: 0.3804\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [40/100], Loss: 0.3790\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [50/100], Loss: 0.3778\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [60/100], Loss: 0.3769\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [70/100], Loss: 0.3760\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [80/100], Loss: 0.3753\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [90/100], Loss: 0.3747\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [100/100], Loss: 0.3741\n",
      "Test Loss: 0.37455472350120544\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [10/100], Loss: 0.3969\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [20/100], Loss: 0.3902\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [30/100], Loss: 0.3895\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [40/100], Loss: 0.3889\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [50/100], Loss: 0.3884\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [60/100], Loss: 0.3879\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [70/100], Loss: 0.3875\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [80/100], Loss: 0.3871\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [90/100], Loss: 0.3867\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [100/100], Loss: 0.3863\n",
      "Test Loss: 0.38655194640159607\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [10/100], Loss: 0.5394\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [20/100], Loss: 0.4016\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [30/100], Loss: 0.3712\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [40/100], Loss: 0.3699\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [50/100], Loss: 0.3679\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [60/100], Loss: 0.3667\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [70/100], Loss: 0.3657\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [80/100], Loss: 0.3650\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [90/100], Loss: 0.3644\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [100/100], Loss: 0.3638\n",
      "Test Loss: 0.36417126655578613\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [10/100], Loss: 0.3820\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [20/100], Loss: 0.3624\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [30/100], Loss: 0.3578\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [40/100], Loss: 0.3561\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [50/100], Loss: 0.3546\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [60/100], Loss: 0.3536\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [70/100], Loss: 0.3529\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [80/100], Loss: 0.3521\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [90/100], Loss: 0.3513\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [100/100], Loss: 0.3505\n",
      "Test Loss: 0.3509882986545563\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [10/100], Loss: 1.6157\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [20/100], Loss: 0.7516\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [30/100], Loss: 0.5039\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [40/100], Loss: 0.4278\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [50/100], Loss: 0.3911\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [60/100], Loss: 0.3809\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [70/100], Loss: 0.3755\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [80/100], Loss: 0.3712\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [90/100], Loss: 0.3693\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [100/100], Loss: 0.3681\n",
      "Test Loss: 0.3683404326438904\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [10/100], Loss: 0.3672\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [20/100], Loss: 0.3610\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [30/100], Loss: 0.3645\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [40/100], Loss: 0.3588\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [50/100], Loss: 0.3595\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [60/100], Loss: 0.3585\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [70/100], Loss: 0.3583\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [80/100], Loss: 0.3586\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [90/100], Loss: 0.3585\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [100/100], Loss: 0.3587\n",
      "Test Loss: 0.35943496227264404\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [10/100], Loss: 0.8607\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [20/100], Loss: 0.7137\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [30/100], Loss: 0.6307\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [40/100], Loss: 0.5766\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [50/100], Loss: 0.5388\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [60/100], Loss: 0.5109\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [70/100], Loss: 0.4897\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [80/100], Loss: 0.4731\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [90/100], Loss: 0.4597\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [100/100], Loss: 0.4487\n",
      "Test Loss: 0.44777700304985046\n",
      "Best Model Loss: 0.3505299389362335, Best Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "\n",
    "# Define a list of optimizer configurations to try\n",
    "optimizer_configs = [\n",
    "    {\"optimizer\": torch.optim.SGD, \"lr\": 0.01},\n",
    "    {\"optimizer\": torch.optim.SGD, \"lr\": 0.001},\n",
    "    {\"optimizer\": torch.optim.SGD, \"lr\": 0.01, \"momentum\": 0.9},\n",
    "    {\"optimizer\": torch.optim.Adam, \"lr\": 0.01},\n",
    "    {\"optimizer\": torch.optim.Adam, \"lr\": 0.001},\n",
    "    {\"optimizer\": torch.optim.RMSprop, \"lr\": 0.01},\n",
    "    {\"optimizer\": torch.optim.RMSprop, \"lr\": 0.0001}\n",
    "]\n",
    "\n",
    "best_nn_model = None\n",
    "best_nn_loss = float('inf')\n",
    "best_optimizer_config = None\n",
    "\n",
    "for config in optimizer_configs:\n",
    "    # Create the neural network model with two hidden layers\n",
    "    nn_model = nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, 1)  # Single output neuron for continuous score\n",
    "    )\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Initialize the optimizer with the current configuration\n",
    "    optimizer = config[\"optimizer\"](nn_model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    if \"momentum\" in config:\n",
    "        optimizer = torch.optim.SGD(nn_model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "\n",
    "    num_epochs = 100\n",
    "    loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        train_inputs = torch.tensor(X_train, dtype=torch.float32)\n",
    "        train_labels = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32)  # Continuous score\n",
    "\n",
    "        # Forward pass\n",
    "        train_outputs = nn_model(train_inputs)\n",
    "        loss = criterion(train_outputs, train_labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training statistics (e.g., loss) as needed\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Configuration: {config}, Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Check if this model has the lowest loss\n",
    "    if loss < best_nn_loss:\n",
    "        best_nn_loss = loss\n",
    "        best_nn_model = nn_model\n",
    "        best_optimizer_config = config\n",
    "        \n",
    "    # Evaluate the best NN model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_inputs = torch.tensor(X_test, dtype=torch.float32)\n",
    "        test_labels = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32)\n",
    "        test_outputs = nn_model(test_inputs)\n",
    "        test_loss = criterion(test_outputs, test_labels)\n",
    "    print(\"Test Loss:\", test_loss.item())\n",
    "\n",
    "# Print the best model's loss and keep it as \"best_model\"\n",
    "print(f\"Best Model Loss: {best_nn_loss}, Best Configuration: {best_optimizer_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa750a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T19:04:54.121582Z",
     "start_time": "2023-11-09T19:04:23.397240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.3597734920240081\n",
      "Ridge MSE: 0.3597726009496486\n",
      "Lasso MSE: 0.3735709224939708\n",
      "Elastic Net MSE: 0.3735709224939708\n",
      "Bayesian Ridge MSE: 0.35977255358364907\n",
      "Extreme Gradient Boosting Regressor MSE: 0.3427200688512837\n",
      "Best Model: Extreme Gradient Boosting Regressor, Best Model MSE: 0.3427200688512837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize variables to track the best model and its MSE\n",
    "best_sk_model = None\n",
    "best_sk_mse = float('inf')\n",
    "best_sk_model_name = None \n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Elastic Net\": ElasticNet(),\n",
    "    \"Bayesian Ridge\": BayesianRidge(),\n",
    "    \"Extreme Gradient Boosting Regressor\": XGBRegressor(objective=\"reg:squarederror\", learning_rate=0.01, n_estimators=2000, max_depth=7)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train);\n",
    "    y_preds = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model performance \n",
    "    model_mse = mean_squared_error(y_preds, y_test)\n",
    "    print(f\"{model_name} MSE:\", model_mse)\n",
    "\n",
    "    # Check if this model has the lowest MSE\n",
    "    if model_mse < best_sk_mse:\n",
    "        best_sk_mse = model_mse\n",
    "        best_sk_model = model\n",
    "        best_sk_model_name = model_name\n",
    "\n",
    "# Print the best model's MSE and store it as \"best_model\"\n",
    "print(f\"Best Model: {best_sk_model_name}, Best Model MSE: {best_sk_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89799ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T19:05:30.963269Z",
     "start_time": "2023-11-09T19:04:54.128630Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Create and fit new model to all available data\n",
    "final_model = XGBRegressor(objective=\"reg:squarederror\", learning_rate=0.01, n_estimators=2000, max_depth=7)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Save the best_sk_model to a file\n",
    "model_filename = \"agent_model.pkl\"\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(final_model, file)\n",
    "\n",
    "scaler_filename = \"scaler.pkl\"\n",
    "with open(scaler_filename, 'wb') as file:\n",
    "    joblib.dump(scaler, file);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
