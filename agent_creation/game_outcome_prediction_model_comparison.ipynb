{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa1e2b16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T20:50:50.547180Z",
     "start_time": "2023-11-09T20:50:49.959694Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file, including the first row\n",
    "data = pd.read_csv('board_evals.csv', header=None)\n",
    "\n",
    "# Define the column names as a list\n",
    "column_names = ['Score', 'Captured', 'Potential', 'Regular Pawns', 'Kings', 'Capturables', 'Semi Capturables', 'Uncapturables', 'At Middle', 'Far', 'Is Over', 'Outcome']\n",
    "data.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8326e461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T20:50:50.614735Z",
     "start_time": "2023-11-09T20:50:50.554714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Score  Captured  Potential  Regular Pawns  Kings  Capturables  \\\n",
      "0 -1.606480         0          1              0      0            0   \n",
      "1 -1.547084         0          0              0      0            0   \n",
      "2 -1.665875         0          1              0      0            0   \n",
      "3 -1.844062         0         -1              0      0            0   \n",
      "4 -1.309502         0          2              0      0            0   \n",
      "5 -1.428293         0          7              0      0            0   \n",
      "6 -0.715548         1          8              1      0           -1   \n",
      "7 -1.190711         1          0              0      0            0   \n",
      "8 -1.250107         1         -2              0      0            0   \n",
      "9 -1.190711         1          4              0      0            0   \n",
      "\n",
      "   Semi Capturables  Uncapturables  At Middle  Far  Is Over  Outcome  \n",
      "0                 1             -1          1    0        0       -1  \n",
      "1                 0              1          0    0        0        1  \n",
      "2                 0              0          0    0        0       -1  \n",
      "3                 1             -1          0    0        0        1  \n",
      "4                 0              1          1    0        0       -1  \n",
      "5                 2             -2          0    0        0        1  \n",
      "6                 1              0          0    1        0       -1  \n",
      "7                 3             -1          1    0        0        1  \n",
      "8                 1              2         -1    0        0       -1  \n",
      "9                 4             -3          1    0        0        1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Scale the first column values\n",
    "scaler = StandardScaler()\n",
    "data['Score'] = scaler.fit_transform(np.array(data[['Score']]))\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20dc378c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T20:50:50.956425Z",
     "start_time": "2023-11-09T20:50:50.625384Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and the target (y)\n",
    "X = np.array(data.drop(columns=['Outcome']))  # Features (all columns except 'Outcome')\n",
    "y = np.array(data['Outcome'])  # Target variable ('Outcome' column)\n",
    "\n",
    "# Split the data into training (70%) and test (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc29ef5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T20:54:20.849362Z",
     "start_time": "2023-11-09T20:50:50.964710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [10/100], Loss: 0.3942\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [20/100], Loss: 0.3871\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [30/100], Loss: 0.3827\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [40/100], Loss: 0.3796\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [50/100], Loss: 0.3774\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [60/100], Loss: 0.3756\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [70/100], Loss: 0.3742\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [80/100], Loss: 0.3731\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [90/100], Loss: 0.3722\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}, Epoch [100/100], Loss: 0.3714\n",
      "Test Loss: 0.37197041511535645\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [10/100], Loss: 0.4307\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [20/100], Loss: 0.4198\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [30/100], Loss: 0.4129\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [40/100], Loss: 0.4082\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [50/100], Loss: 0.4050\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [60/100], Loss: 0.4026\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [70/100], Loss: 0.4007\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [80/100], Loss: 0.3992\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [90/100], Loss: 0.3980\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.001}, Epoch [100/100], Loss: 0.3969\n",
      "Test Loss: 0.3978192210197449\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [10/100], Loss: 0.4115\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [20/100], Loss: 0.3843\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [30/100], Loss: 0.3714\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [40/100], Loss: 0.3670\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [50/100], Loss: 0.3656\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [60/100], Loss: 0.3646\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [70/100], Loss: 0.3637\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [80/100], Loss: 0.3629\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [90/100], Loss: 0.3623\n",
      "Configuration: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01, 'momentum': 0.9}, Epoch [100/100], Loss: 0.3617\n",
      "Test Loss: 0.3620358407497406\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [10/100], Loss: 0.4507\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [20/100], Loss: 0.3806\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [30/100], Loss: 0.3610\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [40/100], Loss: 0.3597\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [50/100], Loss: 0.3575\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [60/100], Loss: 0.3557\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [70/100], Loss: 0.3545\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [80/100], Loss: 0.3536\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [90/100], Loss: 0.3528\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}, Epoch [100/100], Loss: 0.3522\n",
      "Test Loss: 0.35255885124206543\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [10/100], Loss: 0.8541\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [20/100], Loss: 0.4922\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [30/100], Loss: 0.4182\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [40/100], Loss: 0.3857\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [50/100], Loss: 0.3803\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [60/100], Loss: 0.3762\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [70/100], Loss: 0.3718\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [80/100], Loss: 0.3703\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [90/100], Loss: 0.3690\n",
      "Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}, Epoch [100/100], Loss: 0.3680\n",
      "Test Loss: 0.36844828724861145\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [10/100], Loss: 0.3800\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [20/100], Loss: 0.3666\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [30/100], Loss: 0.3647\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [40/100], Loss: 0.3621\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [50/100], Loss: 0.3613\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [60/100], Loss: 0.3601\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [70/100], Loss: 0.3595\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [80/100], Loss: 0.3588\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [90/100], Loss: 0.3590\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.01}, Epoch [100/100], Loss: 0.3584\n",
      "Test Loss: 0.3590880036354065\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [10/100], Loss: 0.4208\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [20/100], Loss: 0.4016\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [30/100], Loss: 0.3946\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [40/100], Loss: 0.3903\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [50/100], Loss: 0.3871\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [60/100], Loss: 0.3846\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [70/100], Loss: 0.3824\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [80/100], Loss: 0.3806\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [90/100], Loss: 0.3791\n",
      "Configuration: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'lr': 0.0001}, Epoch [100/100], Loss: 0.3778\n",
      "Test Loss: 0.3783389925956726\n",
      "Best Model Loss: 0.3521813750267029, Best Configuration: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "\n",
    "# Define a list of optimizer configurations to try\n",
    "optimizer_configs = [\n",
    "    {\"optimizer\": torch.optim.SGD, \"lr\": 0.01},\n",
    "    {\"optimizer\": torch.optim.SGD, \"lr\": 0.001},\n",
    "    {\"optimizer\": torch.optim.SGD, \"lr\": 0.01, \"momentum\": 0.9},\n",
    "    {\"optimizer\": torch.optim.Adam, \"lr\": 0.01},\n",
    "    {\"optimizer\": torch.optim.Adam, \"lr\": 0.001},\n",
    "    {\"optimizer\": torch.optim.RMSprop, \"lr\": 0.01},\n",
    "    {\"optimizer\": torch.optim.RMSprop, \"lr\": 0.0001}\n",
    "]\n",
    "\n",
    "best_nn_model = None\n",
    "best_nn_loss = float('inf')\n",
    "best_optimizer_config = None\n",
    "\n",
    "for config in optimizer_configs:\n",
    "    # Create the neural network model with two hidden layers\n",
    "    nn_model = nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, 1)  # Single output neuron for continuous score\n",
    "    )\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Initialize the optimizer with the current configuration\n",
    "    optimizer = config[\"optimizer\"](nn_model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    if \"momentum\" in config:\n",
    "        optimizer = torch.optim.SGD(nn_model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "\n",
    "    num_epochs = 100\n",
    "    loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        train_inputs = torch.tensor(X_train, dtype=torch.float32)\n",
    "        train_labels = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32)  # Continuous score\n",
    "\n",
    "        # Forward pass\n",
    "        train_outputs = nn_model(train_inputs)\n",
    "        loss = criterion(train_outputs, train_labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training statistics (e.g., loss) as needed\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Configuration: {config}, Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Check if this model has the lowest loss\n",
    "    if loss < best_nn_loss:\n",
    "        best_nn_loss = loss\n",
    "        best_nn_model = nn_model\n",
    "        best_optimizer_config = config\n",
    "        \n",
    "    # Evaluate the best NN model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_inputs = torch.tensor(X_test, dtype=torch.float32)\n",
    "        test_labels = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32)\n",
    "        test_outputs = nn_model(test_inputs)\n",
    "        test_loss = criterion(test_outputs, test_labels)\n",
    "    print(\"Test Loss:\", test_loss.item())\n",
    "\n",
    "# Print the best model's loss and keep it as \"best_model\"\n",
    "print(f\"Best Model Loss: {best_nn_loss}, Best Configuration: {best_optimizer_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aa750a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T20:54:50.634069Z",
     "start_time": "2023-11-09T20:54:20.854478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.3597734920240081\n",
      "Ridge MSE: 0.3597726009496486\n",
      "Lasso MSE: 0.3735709224939708\n",
      "Elastic Net MSE: 0.3735709224939708\n",
      "Bayesian Ridge MSE: 0.35977255358364907\n",
      "Extreme Gradient Boosting Regressor MSE: 0.3427200688512837\n",
      "Best Model: Extreme Gradient Boosting Regressor, Best Model MSE: 0.3427200688512837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize variables to track the best model and its MSE\n",
    "best_sk_model = None\n",
    "best_sk_mse = float('inf')\n",
    "best_sk_model_name = None \n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Elastic Net\": ElasticNet(),\n",
    "    \"Bayesian Ridge\": BayesianRidge(),\n",
    "    \"Extreme Gradient Boosting Regressor\": XGBRegressor(objective=\"reg:squarederror\", learning_rate=0.01, n_estimators=2000, max_depth=7)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train);\n",
    "    y_preds = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model performance \n",
    "    model_mse = mean_squared_error(y_preds, y_test)\n",
    "    print(f\"{model_name} MSE:\", model_mse)\n",
    "\n",
    "    # Check if this model has the lowest MSE\n",
    "    if model_mse < best_sk_mse:\n",
    "        best_sk_mse = model_mse\n",
    "        best_sk_model = model\n",
    "        best_sk_model_name = model_name\n",
    "\n",
    "# Print the best model's MSE and store it as \"best_model\"\n",
    "print(f\"Best Model: {best_sk_model_name}, Best Model MSE: {best_sk_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/150], Loss: 0.4009\n",
      "Epoch [20/150], Loss: 0.3735\n",
      "Epoch [30/150], Loss: 0.3619\n",
      "Epoch [40/150], Loss: 0.3575\n",
      "Epoch [50/150], Loss: 0.3556\n",
      "Epoch [60/150], Loss: 0.3543\n",
      "Epoch [70/150], Loss: 0.3532\n",
      "Epoch [80/150], Loss: 0.3524\n",
      "Epoch [90/150], Loss: 0.3517\n",
      "Epoch [100/150], Loss: 0.3512\n",
      "Epoch [110/150], Loss: 0.3507\n",
      "Epoch [120/150], Loss: 0.3503\n",
      "Epoch [130/150], Loss: 0.3500\n",
      "Epoch [140/150], Loss: 0.3496\n",
      "Epoch [150/150], Loss: 0.3493\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim  # Import Adam optimizer directly\n",
    "\n",
    "# Create the neural network model with the best configuration\n",
    "best_optimizer_config = {\"optimizer\": optim.Adam, \"lr\": 0.01}\n",
    "\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 64\n",
    "\n",
    "final_model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, 1)  # Single output neuron for continuous score\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Initialize the optimizer with the best configuration\n",
    "optimizer = best_optimizer_config[\"optimizer\"](final_model.parameters(), lr=best_optimizer_config[\"lr\"])\n",
    "\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.tensor(X, dtype=torch.float32)\n",
    "    labels = torch.tensor(y.reshape(-1, 1), dtype=torch.float32)  # Continuous score\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = final_model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print training statistics (e.g., loss) as needed\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T20:57:35.920121Z",
     "start_time": "2023-11-09T20:56:31.791332Z"
    }
   },
   "id": "bf8944a5b3d38032"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "#Save the scaler and the model\n",
    "scaler_filename = \"scaler.pkl\"\n",
    "with open(scaler_filename, 'wb') as file:\n",
    "    joblib.dump(scaler, file);\n",
    "    \n",
    "torch.save(final_model, \"agent_model.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T20:57:35.929744Z",
     "start_time": "2023-11-09T20:57:35.923173Z"
    }
   },
   "id": "74537ad857d533e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
